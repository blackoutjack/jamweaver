#!/usr/bin/python
#
# This script is used to analyze, tabulate, and graph data generated by
# the JAM weaver and by JAMScript performance instrumentation. It was
# used to produce figures presented in the experimental results section
# of ``Efficient Runtime Enforcement Techniques for Policy Weaving,''
# published at FSE 2014.
#

import sys
MAJOR = sys.version_info[0]

import os
import re
import subprocess
from subprocess import PIPE
import shutil
import time
import imp
from optparse import OptionParser
#import warnings

import grapher

from resultsutil import AppStats, SourceVariant, Action, Section

def collect_results_from_file(filepath, results):
  lns = cfg.get_lines(filepath)
    
  # Detect whether the file contains any results via the format.
  # %%% Does this short-circuit when it finds a match?
  isresults = any([True for ln in lns if ln.startswith(cfg.PROFILE_MARKER)])
  if isresults:
    results.extend(lns)

def collect_results(filelist):
  lines = []
  for respath in filelist:
    assert os.path.exists(respath), "Results source does not exist: %s" % respath
    collect_results_from_file(respath, lines)

  if len(lines) == 0:
    cfg.warn("No results found")

  return lines
#/collect_results

def collect_separate_results(filelist):
  results = []
  for respath in filelist:
    lines = []
    assert os.path.exists(respath), "Results source does not exist: %s" % respath
    collect_results_from_file(respath, lines)
    if len(lines) == 0:
      cfg.warn("No results found for file: %s" % respath)
    results.append(lines)

  return results
#/collect_separate_results

def parse_profile_header(ln):
  assert ln.startswith(cfg.PROFILE_MARKER)
  action = ln[len(cfg.PROFILE_MARKER):-len(cfg.PROFILE_MARKER_TAIL)]
  if len(action) < 1:
    cfg.err("Action name is empty: %s" % ln)
  return action
#/parse_profile_header

def parse_section_header(ln):
  assert ln.startswith(cfg.SECTION_MARKER)
  info = None
  section = ln[len(cfg.SECTION_MARKER):-len(cfg.SECTION_MARKER)]
  if section.startswith(cfg.TIME_SECTION_NAME):
    info = section[len(cfg.TIME_SECTION_NAME):]
    info = info.lstrip(": ")
    section = cfg.TIME_SECTION_NAME
  if len(section) < 1:
    cfg.err("Section name is empty: %s" % ln)

  return section, info
#/parse_section_header

def parse_stack(lines):
  appinfo = None
  stackinfo = [] # Will contain (file, lineno) pairs in order.
  for ln in lines:
    parts = ln.split(None)
    # This can happen for unknown stack frames.
    if len(parts) < 3: continue
    flln = parts[2]
    srcfl, lineno = flln.rsplit(':', 1)
    stackinfo.append((srcfl, lineno))
  for i in range(0, len(stackinfo)):
    idx = len(stackinfo) - 1 - i
    lastsrc = stackinfo[idx][0]
    if lastsrc.startswith('http://'):
      lastsrc = lastsrc[7:]
    # Get the init time.
    # %%% Ugly string matching
    if lastsrc.startswith(cfg.TEST_DIR):
      lastsrc = lastsrc[len(cfg.TEST_DIR):]

      for marker in ['/test.php?script=', '/test.php?sources[]=']:
        begin = -1
        begin = lastsrc.find(marker)
        if begin > -1:
          begin += len(marker)
          lastsrc = lastsrc[begin:]
          end = lastsrc.find("&policy=")
          if end > -1:
            lastsrc = lastsrc[:end]
          break

    appinfo = cfg.get_file_info(lastsrc)

    if appinfo['app'] != 'libTx' and appinfo['app'] != 'auto' and appinfo['app'] != 'autoextra':
      break

  return appinfo, stackinfo
#/parse_stack

def process_data(appstats, variant, action, section, dataline):
  dataparts = dataline.split('/')
  # This method assumes the first data fed to it has column headers.
  section.addData(dataparts)
#/process_data

def parse_results(lines):
  curAppStats = None
  curVariant = None
  curActionDesc = None
  curAction = None
  curSection = None
  curBig = False

  stats = {}

  idxes = iter(range(0, len(lines)))
  for idx in idxes:
    ln = lines[idx].strip()

    if ln == '':
      continue
    isjunk = False
    for junk in cfg.JUNK_MARKERS:
      if ln.startswith(junk):
        isjunk = True
    if isjunk:
      continue

    if ln.startswith(cfg.ERROR_MARKER):
      errtxt = ln[len(cfg.ERROR_MARKER):]
      if curAction is not None:
        curAction.addError(errtxt)
        cfg.err("Error inkey action %s, variant %s, app %s: %s" % (curAction.description, curVariant.descriptor(), curAppStats.name, errtxt))
      elif curVariant is not None:
        curVariant.addError(errtxt)
        cfg.err("Error in variant %s, app %s: %s" % (curVariant.descriptor(), curAppStats.name, errtxt))
      elif curAppStats is not None:
        curAppStats.addError(errtxt)
        cfg.err("Error in app %s: %s" % (curAppStats.name, errtxt))
      else:
        cfg.err("Unassociated error: %s" % errtxt)
      continue

    if ln.startswith(cfg.PROFILE_MARKER):
      curActionDesc = parse_profile_header(ln)

    elif ln.startswith(cfg.SECTION_MARKER):
      sect, sectinfo = parse_section_header(ln)
      curSection = Section(sect, sectinfo)
      assert curAction is not None
      curAction.addSection(curSection, cfg.TIME_SECTION_NAME)

    elif ln.startswith(cfg.STACK_MARKER):
      stack = [ln]
      # Look ahead to get whole stack.
      nextidx = idx + 1
      while True:
        try:
          nextln = lines[nextidx]
          if nextln.startswith(cfg.STACK_MARKER):
            stack.append(nextln)
            next(idxes) # Exhaust the line from the iterator.
            nextidx += 1
          else:
            break
        except Exception as e:
          cfg.err('While parsing stack: %s' % str(e))
          break
      appinfo, stackInfo = parse_stack(stack)
      # Generate or retrieve the AppStats object.
      appname = appinfo['app']

      # Parse the body HTML to determine whether it's a "big" test case.
      # %%% Yikes!
      if curActionDesc == 'init' and appname.startswith(cfg.SMS2PREFIX):
        if ln.find('.big.body.html') > -1 or appname.endswith('.big'):
          curBig = True
        else:
          curBig = False

      appkey = appname
      if appkey.startswith(cfg.SMS2PREFIX):
        if appkey.endswith('.big') or appkey.endswith('-big'):
          appkey = appkey[:-4]
        if appkey.endswith('-newcall'):
          appkey = appkey[:-8]
      elif appkey == 'jsqrcode-call':
        appkey = 'jsqrcode'

      if appkey in stats:
        curAppStats = stats[appkey]
      else:
        curAppStats = AppStats(appname)
        stats[appkey] = curAppStats
      descparts = appinfo['desc']

      # "profile" is expected for all of these data.
      try: descparts.remove('profile')
      except: cfg.err('No "profile" component of variant description: %r' % appinfo)

      curVariant = curAppStats.getVariant(descparts)
      # The app/variant info is assumed to come right after the action.
      if appname.startswith(cfg.SMS2PREFIX) and curActionDesc == "compute":
        if curBig:
          curActionDesc = "bigcompute"
        
      curAction = curVariant.getAction(curActionDesc, stackInfo)

    else:
      assert curSection is not None, "No section info: %s" % ln
      process_data(curAppStats, curVariant, curAction, curSection, ln)

  return stats
#/parse_results

def print_all_times(stats):
  # Print the time stats for each app.
  for app, stat in stats.items():
    cfg.out(stat.name)
    for i in stat.variants:
      cfg.out(str(stat.variants[i]))

def print_times(app, actdesc, timemap):
  out = '%s/%s' % (app, actdesc)
  for v, t in timemap.items():
    out += ' %s:%s' % (v, str(t))
  cfg.out(out)

def compare_sections(sect0, sect1, action, variant, app):
  allsame = True
  section = sect0.name

  # Compare keys for the two dicts.
  keys0 = set(sect0.rows.keys())
  keys1 = set(sect1.rows.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
    cfg.err("Row '%s' not found in 2nd section '%s', action '%s', variant '%s' for app '%s'" % (a0, section, action, variant, app))
    allsame = False
  for a1 in addl1:
    cfg.err("Row '%s' not found in 2nd section '%s', action '%s', variant '%s' for app '%s'" % (a1, section, action, variant, app))
    allsame = False

  common = keys0 & keys1
  for rowdesc in common:
    rowdata0 = sect0.rows[rowdesc]
    rowdata1 = sect1.rows[rowdesc]
    if rowdata0 != rowdata1:
      cfg.err("Data is inconsistent: %r != %r in section '%s', action '%s', variant '%s', app '%s'" % (rowdata0, rowdata1, section, action, variant, app))
      allsame = False

  return allsame
#/compare_sections

def compare_actions(act0, act1, variant, app):
  allsame = True
  action = act0.description

  # Compare keys for the two dicts.
  keys0 = set(act0.sections.keys())
  keys1 = set(act1.sections.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
    cfg.err("Section '%s' not found for 2nd action '%s' in variant '%s' for app '%s'" % (a0, action, variant, app))
    allsame = False
  for a1 in addl1:
    cfg.err("Section '%s' not found for 1st action '%s' in variant '%s' for app '%s'" % (a1, action, variant, app))
    allsame = False

  common = keys0 & keys1
  for sectdesc in common:
    sectlist0 = act0.sections[sectdesc]
    sectlist1 = act1.sections[sectdesc]
    for sect0 in sectlist0:
      for sect1 in sectlist1:
        if not compare_sections(sect0, sect1, action, variant, app):
          allsame = False

  return allsame
#/compare_actions

def compare_variants(var0, var1, app):
  allsame = True
  variant = var0.descriptor()

  # Compare keys for the two dicts.
  keys0 = set(var0.actions.keys())
  keys1 = set(var1.actions.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
    cfg.err("Action '%s' not found in 2nd variant '%s' for app '%s'" % (a0, variant, app))
    allsame = False
  for a1 in addl1:
    cfg.err("Action '%s' not found in 1st variant '%s' for app '%s'" % (a1, variant, app))
    allsame = False

  common = keys0 & keys1
  for actdesc in common:
    act0 = var0.actions[actdesc]
    act1 = var1.actions[actdesc]
    if not compare_actions(act0, act1, variant, app):
      allsame = False

  return allsame

def compare_stats(statsobj0, statsobj1):
  allsame = True 
  app = statsobj0.name

  # Compare keys for the two dicts.
  keys0 = set(statsobj0.variants.keys())
  keys1 = set(statsobj1.variants.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
    cfg.err("Variant '%s' not found in 2nd variant list for app '%s'" % (a0, app))
    allsame = False
  for a1 in addl1:
    cfg.err("Variant '%s' not found in 1st variant list for app '%s'" % (a1, app))
    allsame = False

  common = keys0 & keys1
  for vardesc in common:
    variant0 = statsobj0.variants[vardesc]
    variant1 = statsobj1.variants[vardesc]
    if not compare_variants(variant0, variant1, app):
      allsame = False

  return allsame
#/compare_stats

def compare_results(stats0, stats1):
  allsame = True

  # Compare keys for the two dicts.
  keys0 = set(stats0.keys())
  keys1 = set(stats1.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
    cfg.err("Application '%s' not found in 2nd stats list" % a0)
    allsame = False
  for a1 in addl1:
    cfg.err("Application '%s' not found in 1st stats list" % a1)
    allsame = False

  common = keys0 & keys1
  for app in common:
    stats0obj = stats0[app]
    stats1obj = stats1[app]
    if not compare_stats(stats0obj, stats1obj):
      allsame = False

  if allsame:
    cfg.out("Statistics match exactly")
#/compare_results

def compare_actions_times(act0, act1, variant, app):
  allsame = True
  action = act0.description
  
  t0 = act0.avg_time()
  t1 = act1.avg_time()
  diff = t0 - t1
  if diff < 0.0:
    fast = -1
    faststr = '0 is faster'
    diff = -diff
    ratio = t0 / t1
  elif diff > 0.0:
    fast = 1
    faststr = '1 is faster'
    ratio = t1 / t0
  else:
    fast = 0
    faststr = 'Same time'
    ratio = 1.0
    
  cfg.out("%s for app '%s', variant '%s', action '%s', difference: %.2f, ratio: %.2f" % (faststr, app, variant, action, diff, ratio))
  return (fast, diff, ratio)
#/compare_actions_times

def compare_variants_times(var0, var1, app):
  allsame = True
  variant = var0.descriptor()

  # Compare keys for the two dicts.
  keys0 = set(var0.actions.keys())
  keys1 = set(var1.actions.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
    cfg.err("Action '%s' not found in 2nd variant '%s' for app '%s'" % (a0, variant, app))
  for a1 in addl1:
    cfg.err("Action '%s' not found in 1st variant '%s' for app '%s'" % (a1, variant, app))

  common = keys0 & keys1
  for actdesc in common:
    act0 = var0.actions[actdesc]
    act1 = var1.actions[actdesc]
    fast, diff, ratio = compare_actions_times(act0, act1, variant, app)
    # %%% Do something with these
#/compare_variants_times

def compare_stats_times(statsobj0, statsobj1):
  app = statsobj0.name

  # Compare keys for the two dicts.
  keys0 = set(statsobj0.variants.keys())
  keys1 = set(statsobj1.variants.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
      cfg.err("Variant '%s' not found in 2nd variant list for app '%s'" % (a0, app))
  for a1 in addl1:
      cfg.err("Variant '%s' not found in 1st variant list for app '%s'" % (a1, app))

  common = keys0 & keys1
  for vardesc in common:
    variant0 = statsobj0.variants[vardesc]
    variant1 = statsobj1.variants[vardesc]
    compare_variants_times(variant0, variant1, app)
#/compare_stats_times

def compare_times(stats0, stats1):
  # Compare keys for the two dicts.
  keys0 = set(stats0.keys())
  keys1 = set(stats1.keys())
  addl0 = keys0 - keys1
  addl1 = keys1 - keys0
  for a0 in addl0:
      cfg.err("Application '%s' not found in 2nd stats list" % a0)
  for a1 in addl1:
      cfg.err("Application '%s' not found in 1st stats list" % a1)

  common = keys0 & keys1
  for app in common:
    stats0obj = stats0[app]
    stats1obj = stats1[app]
    compare_stats_times(stats0obj, stats1obj)
#/compare_times

# Get a list of actions recorded in the given |AppStats| object.
def load_actions(stat):
  actions = []
  for vardesc in stat.variants:
    for actdesc in stat.variants[vardesc].actions:
      if actdesc not in actions:
        actions.append(actdesc)
  return actions

# Get a filtered list of variants for the given application/action.
# An exception may be thrown if some variants are not available.
def load_variants(stat, actdesc):
  app = stat.name
  variants = {}
  for vardesc in cfg.VARIANTS:
    if vardesc in stat.variants:
      variant = stat.variants[vardesc]
      if actdesc not in variant.actions:
        raise Exception("Data not available for action: %s %s %s" % (app, vardesc, actdesc))
      variants[vardesc] = variant
    else:
      raise Exception("Variant data not available: %s %s" % (app, vardesc))
      
  assert len(variants) == len(cfg.VARIANTS)
  return variants

def print_time_comparison(stats):
  apps = stats.keys()
  apps.sort()
  for app in apps:
    stat = stats[app]
    actdescs = load_actions(stat)
    for actdesc in actdescs:
      try:
        variants = load_variants(stat, actdesc)
        times = {}
        for vardesc, variant in variants.items():
          times[vardesc] = variant.actions[actdesc].avg_time()
        print_times(app, actdesc, times)
      except Exception as e:
        cfg.err('Time comparison for %s/%s: %s' (app, actdesc, str(e)))

def updateMinMax(minmax, tm, sub, desc):
  curmin = minmax[sub]['mintime'] 
  if tm < curmin:
    minmax[sub]['mintime'] = tm
    minmax[sub]['minapp'] = desc
  
  curmax = minmax[sub]['maxtime']
  if tm > curmax:
    minmax[sub]['maxtime'] = tm
    minmax[sub]['maxapp'] = desc

# Create graphs.
def generate_graphs(stats):
  timelist = []
  apps = list(stats.keys())
  apps.sort()
  minmax = {
    'overall': {
      'mintime': float('inf'),
      'maxtime': 0.0,
      'minapp': None,
      'maxapp': None,
    },
    'init': {
      'mintime': float('inf'),
      'maxtime': 0.0,
      'minapp': None,
      'maxapp': None,
    }
  }
  for app in apps:
    if app in cfg.DISABLED:
      continue
    stat = stats[app]
    actdescs = load_actions(stat)
    for actdesc in actdescs:
      # Optionally group init and load times together
      if cfg.INCLUDE_INIT and actdesc == 'init': continue
      if cfg.SUPPRESS_SMS2_LOAD and actdesc == 'load' and app.startswith(cfg.SMS2PREFIX): continue

      variants = load_variants(stat, actdesc)
      times = {}
      times['action'] = actdesc
      for vardesc, variant in variants.items():
        tm = variant.actions[actdesc].avg_time()
        desc = app + '/' + actdesc + '/' + vardesc

        # Optionally add on policy.js and libTx.js load time.
        if cfg.INCLUDE_INIT:
          if actdesc == 'load' and vardesc != 'input':
            if 'init' in variant.actions:
              inittm = variant.actions['init'].avg_time() 
              updateMinMax(minmax, inittm, 'init', desc)
              tm += inittm
            else:
              cfg.warn("No init time for load: %s/%s" % (app, vardesc))
        elif actdesc == 'init' and vardesc != 'input':
          updateMinMax(minmax, inittm, 'init', desc)

        times[vardesc] = tm
        updateMinMax(minmax, tm, 'overall', desc)

      # Check for zero/negative times.
      ok = True
      for vardesc, time in times.items():
        if vardesc == 'action': continue
        if time <= 0:
          cfg.err("NON-POSITIVE TIME: %s/%s/%s/%.2f" % (app, actdesc, vardesc, time))
          ok = False
      if not ok: continue

      # Check for cases where woven performs worse than modular
      # on long-duration base case.
      time0 = float(times[cfg.VARIANTS[0]])
      time1 = float(times[cfg.VARIANTS[1]])
      time2 = float(times[cfg.VARIANTS[2]])
      disp0 = cfg.VARIANT_DISPLAY[0].upper()
      disp1 = cfg.VARIANT_DISPLAY[1].upper()
      disp2 = cfg.VARIANT_DISPLAY[2].upper()
      if time2 > time1 and time0 > 100.0:
        cfg.warn("LONG-DURATION OUTLIER: %s/%s/%.2f/%.2f/%.2f" % (app, actdesc, time0, time1, time2))

      if actdesc != 'init' and time0 < 0.1 or time1 < 0.1 or time2 < 0.1:
        cfg.warn("TINY TIME: %s/%s/%.2f/%.2f/%.2f" % (app, actdesc, time0, time1, time2))

      # Check for cases where secure code is faster than unprotected.
      if actdesc != 'init' and time2 / time0 <= 0.90:
        cfg.warn("%s UNDERLIER: %s/%s %.2f" % (disp2, app, actdesc, time2 / time0))

      if actdesc != 'init' and time1 / time0 < 0.90:
        cfg.warn("%s UNDERLIER: %s/%s %.2f" % (disp1, app, actdesc, time1 / time0))

      if time2 / time1 > 1.5:
        cfg.warn("LARGE %s/%s RATIO: %s/%s/%.2f/%.2f" % (disp2, disp1, app, actdesc, time2 / time1, time0))

      if actdesc != 'init' and actdesc != 'load' and time2 / time0 > 5:
        cfg.warn("LARGE %s/%s RATIO: %s/%s/%.2f" % (disp2, disp0, app, actdesc, time2 / time0))

      timelist.append(times)

  grapher.modularVsWovenOverheadByOriginal(timelist, cfg.VARIANTS, cfg.VARIANT_DISPLAY)
  #grapher.modularVsWovenOverhead(timelist, False)
  grapher.modularVsWovenOverhead(timelist, True)
  grapher.wovenOverheadByOriginal(timelist, cfg.VARIANTS, cfg.VARIANT_DISPLAY)

  cfg.out("MIN INIT TIME: %s/%s" % (minmax['init']['mintime'], minmax['init']['minapp']))
  cfg.out("MAX INIT TIME: %s/%s" % (minmax['init']['maxtime'], minmax['init']['maxapp']))
  cfg.out("MIN ACTION TIME: %s/%s" % (minmax['overall']['mintime'], minmax['overall']['minapp']))
  cfg.out("MAX ACTION TIME: %s/%s" % (minmax['overall']['maxtime'], minmax['overall']['maxapp']))
#/generate_graphs

def generate_output(stats):
  #print_all_times(stats)
  #print_time_comparison(stats)
  generate_graphs(stats)
#/generate_output

def main():
  parser = OptionParser(usage="%prog results.txt")
  parser.add_option('-c', '--config', action='store', default=os.path.join(os.path.dirname(__file__), 'resultsconfig.py'), dest='config', help='configuration.py file')
  parser.add_option('-v', '--verbose', action='store_true', default=False, dest='verbose', help='generate verbose output')
  parser.add_option('-a', '--analysis', action='store', default='t', dest='analysis', help='t: fine-grained vs. coarsed-grain runtime; c: compare profile information across results files; m: compare running time across results files; a: all')

  opts, args = parser.parse_args()
  #warnings.simplefilter('error', UserWarning)
  global cfg
  cfg = imp.load_source("cfg", opts.config)

  global VERBOSE
  VERBOSE = opts.verbose

  analysis = opts.analysis
  if analysis not in ['a', 't', 'c', 'm']:
    parser.error("Invalid analysis identifier: %s" % analysis)
    
  if len(args) == 0:
    assert os.path.exists(cfg.RESULTS_SOURCE), "Default results path %s doesn't exist." % cfg.RESULTS_SOURCE
    resultsfiles = [os.path.join(cfg.RESULTS_SOURCE, fl) for fl in os.listdir(cfg.RESULTS_SOURCE)]
  else:
    resultsfiles = []
    for resfile in args:
      if not os.path.exists(resfile):
        cfg.warn("results file %s doesn't exist." % resfile)
      if os.path.isdir(resfile):
        # Doesn't recurse.
        resultsfiles.extend([os.path.join(resfile, filename) for filename in os.listdir(resfile)])
      else:
        resultsfiles.append(resfile)

  if len(resultsfiles) == 0:
    parser.error("No results files found")

  if analysis == 'a' or analysis == 't':
    resultstxt = collect_results(resultsfiles)
    stats = parse_results(resultstxt)
    generate_output(stats)

  if analysis in ['a', 'c', 'm']:
    if len(resultsfiles) != 2: parser.error("Size of results list != 2")
    resultslist = collect_separate_results(resultsfiles)
    stats0 = parse_results(resultslist[0])
    stats1 = parse_results(resultslist[1])
    if analysis in ['a', 'c']:
      compare_results(stats0, stats1)
    if analysis in ['a', 'm']:
      compare_times(stats0, stats1)
#/main

if __name__ == "__main__":
  main()
